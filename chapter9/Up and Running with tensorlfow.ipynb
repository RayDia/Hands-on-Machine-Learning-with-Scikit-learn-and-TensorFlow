{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "x = tf.Variable(3, name = \"x\")\n",
    "y = tf.Variable(4, name = \"y\")\n",
    "f = x * x * y + 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38\n"
     ]
    }
   ],
   "source": [
    "sess = tf.Session()\n",
    "sess.run(x.initializer)\n",
    "sess.run(y.initializer)\n",
    "result = sess.run(f)\n",
    "print(result)\n",
    "sess.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    x.initializer.run()\n",
    "    y.initializer.run()\n",
    "    result  = f.eval()\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "变量初始化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "init = tf.global_variables_initializer()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    result = f.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 管理图"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "<tensorflow.python.framework.ops.Graph object at 0x7f88950623c8>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.framework.ops.Graph at 0x7f8853ea62e8>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x1 = tf.Variable(1)\n",
    "print(x1.graph is tf.get_default_graph())\n",
    "\n",
    "graph = tf.Graph()\n",
    "with graph.as_default():\n",
    "    x2 = tf.Variable(2)\n",
    "print(x1.graph)    \n",
    "x2.graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 计算节点的生命周期 Lifecycle of a Node Value\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "225\n"
     ]
    }
   ],
   "source": [
    "w = tf.constant(3)\n",
    "x = w + 2\n",
    "y = x * 9\n",
    "z = x * y\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    print(z.eval())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 用TF解决线性回归问题 Linear Regression with TensorFlow\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "\n",
    "housing = fetch_california_housing()\n",
    "m, n = housing.data.shape\n",
    "housing_data_plus_bias = np.c_[np.ones((m, 1)), housing.data]\n",
    "\n",
    "X = tf.constant(housing_data_plus_bias, dtype=tf.float32, name=\"X\")\n",
    "y = tf.constant(housing.target.reshape(-1, 1), dtype=tf.float32, name=\"y\")\n",
    "XT = tf.transpose(X)\n",
    "# θ = (XT · X)–1 · XT · y\n",
    "theta = tf.matmul(tf.matmul(tf.matrix_inverse(tf.matmul(XT, X)), XT), y)\n",
    "with tf.Session() as sess:\n",
    "    theta_value = theta.eval()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 梯度下降 \n",
    "### Manually Computing the Gradients\n",
    "\n",
    "需要特征缩放，使用sklearn的StandardScaler来特征缩放"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 MSE =  9.555813\n",
      "Epoch 100 MSE =  0.7359047\n",
      "Epoch 200 MSE =  0.5772647\n",
      "Epoch 300 MSE =  0.56097335\n",
      "Epoch 400 MSE =  0.55086106\n",
      "Epoch 500 MSE =  0.5435743\n",
      "Epoch 600 MSE =  0.5383\n",
      "Epoch 700 MSE =  0.53448063\n",
      "Epoch 800 MSE =  0.5317129\n",
      "Epoch 900 MSE =  0.52970576\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaled_housing_data = scaler.fit_transform(housing.data)\n",
    "scaled_housing_data_plus_bias = np.c_[np.ones((m, 1)), scaled_housing_data]\n",
    "\n",
    "\n",
    "n_epochs = 1000\n",
    "learning_rate = 0.01\n",
    "\n",
    "X = tf.constant(scaled_housing_data_plus_bias, dtype=tf.float32, name=\"X\")\n",
    "y = tf.constant(housing.target.reshape(-1, 1), dtype=tf.float32, name=\"y\")\n",
    "theta = tf.Variable(tf.random_uniform([n + 1, 1], -1.0, 1.0), name = \"theta\")\n",
    "y_pred = tf.matmul(X, theta, name=\"predictions\")\n",
    "error = y_pred - y\n",
    "mse = tf.reduce_mean(tf.square(error), name=\"mse\")\n",
    "gradients = 2 / m * tf.matmul(tf.transpose(X), error)\n",
    "training_op = tf.assign(theta, theta - learning_rate*gradients)\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    \n",
    "    for epoch in range(n_epochs):\n",
    "        if epoch % 100 == 0:\n",
    "            print(\"Epoch\", epoch, \"MSE = \", mse.eval())\n",
    "        sess.run(training_op)\n",
    "    best_theta = theta.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 使用 自动微分法autodiff\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 MSE = 8.6325445\n",
      "[[-4.4384294 ]\n",
      " [-2.6223013 ]\n",
      " [-0.7782153 ]\n",
      " [ 0.10779657]\n",
      " [ 1.2499629 ]\n",
      " [ 1.7100307 ]\n",
      " [ 0.55459267]\n",
      " [-0.5326979 ]\n",
      " [ 1.1299009 ]]\n",
      "[array([[-4.4384294 ],\n",
      "       [-2.6223013 ],\n",
      "       [-0.7782153 ],\n",
      "       [ 0.10779657],\n",
      "       [ 1.2499629 ],\n",
      "       [ 1.7100307 ],\n",
      "       [ 0.55459267],\n",
      "       [-0.5326979 ],\n",
      "       [ 1.1299009 ]], dtype=float32)]\n",
      "Epoch 100 MSE = 0.7095024\n",
      "[[-0.5886214 ]\n",
      " [-0.34870744]\n",
      " [-0.02075823]\n",
      " [ 0.01459869]\n",
      " [ 0.11869746]\n",
      " [ 0.18805727]\n",
      " [ 0.06130667]\n",
      " [ 0.09306485]\n",
      " [ 0.11236905]]\n",
      "[array([[-0.5886214 ],\n",
      "       [-0.34870744],\n",
      "       [-0.02075823],\n",
      "       [ 0.01459869],\n",
      "       [ 0.11869746],\n",
      "       [ 0.18805727],\n",
      "       [ 0.06130667],\n",
      "       [ 0.09306485],\n",
      "       [ 0.11236905]], dtype=float32)]\n",
      "Epoch 200 MSE = 0.5682746\n",
      "[[-0.07806297]\n",
      " [-0.04300554]\n",
      " [ 0.01235042]\n",
      " [ 0.01654888]\n",
      " [-0.00367407]\n",
      " [ 0.02914782]\n",
      " [ 0.00586761]\n",
      " [ 0.07261223]\n",
      " [ 0.07254743]]\n",
      "[array([[-0.07806297],\n",
      "       [-0.04300554],\n",
      "       [ 0.01235042],\n",
      "       [ 0.01654888],\n",
      "       [-0.00367407],\n",
      "       [ 0.02914782],\n",
      "       [ 0.00586761],\n",
      "       [ 0.07261223],\n",
      "       [ 0.07254743]], dtype=float32)]\n",
      "Epoch 300 MSE = 0.55664164\n",
      "[[-0.01035393]\n",
      " [-0.00408282]\n",
      " [ 0.01000199]\n",
      " [ 0.01316108]\n",
      " [-0.01500383]\n",
      " [ 0.00731014]\n",
      " [-0.00016577]\n",
      " [ 0.06167853]\n",
      " [ 0.06209057]]\n",
      "[array([[-0.01035393],\n",
      "       [-0.00408282],\n",
      "       [ 0.01000199],\n",
      "       [ 0.01316108],\n",
      "       [-0.01500383],\n",
      "       [ 0.00731014],\n",
      "       [-0.00016577],\n",
      "       [ 0.06167853],\n",
      "       [ 0.06209057]], dtype=float32)]\n",
      "Epoch 400 MSE = 0.54944104\n",
      "[[-0.00137322]\n",
      " [ 0.00117427]\n",
      " [ 0.00774552]\n",
      " [ 0.00959613]\n",
      " [-0.01318556]\n",
      " [ 0.00344757]\n",
      " [-0.00065186]\n",
      " [ 0.05408876]\n",
      " [ 0.05446644]]\n",
      "[array([[-0.00137322],\n",
      "       [ 0.00117427],\n",
      "       [ 0.00774552],\n",
      "       [ 0.00959613],\n",
      "       [-0.01318556],\n",
      "       [ 0.00344757],\n",
      "       [-0.00065186],\n",
      "       [ 0.05408876],\n",
      "       [ 0.05446644]], dtype=float32)]\n",
      "Epoch 500 MSE = 0.54396886\n",
      "[[-0.0001826 ]\n",
      " [ 0.00219838]\n",
      " [ 0.00640831]\n",
      " [ 0.00666956]\n",
      " [-0.01023964]\n",
      " [ 0.00243681]\n",
      " [-0.00059836]\n",
      " [ 0.04768145]\n",
      " [ 0.04793719]]\n",
      "[array([[-0.0001826 ],\n",
      "       [ 0.00219838],\n",
      "       [ 0.00640831],\n",
      "       [ 0.00666956],\n",
      "       [-0.01023964],\n",
      "       [ 0.00243681],\n",
      "       [-0.00059836],\n",
      "       [ 0.04768145],\n",
      "       [ 0.04793719]], dtype=float32)]\n",
      "Epoch 600 MSE = 0.53976834\n",
      "[[-2.6193215e-05]\n",
      " [ 2.6113805e-03]\n",
      " [ 5.4820050e-03]\n",
      " [ 4.3265256e-03]\n",
      " [-7.6340223e-03]\n",
      " [ 1.9915013e-03]\n",
      " [-5.2409229e-04]\n",
      " [ 4.2102177e-02]\n",
      " [ 4.2243484e-02]]\n",
      "[array([[-2.6193215e-05],\n",
      "       [ 2.6113805e-03],\n",
      "       [ 5.4820050e-03],\n",
      "       [ 4.3265256e-03],\n",
      "       [-7.6340223e-03],\n",
      "       [ 1.9915013e-03],\n",
      "       [-5.2409229e-04],\n",
      "       [ 4.2102177e-02],\n",
      "       [ 4.2243484e-02]], dtype=float32)]\n",
      "Epoch 700 MSE = 0.5365259\n",
      "[[-1.1855693e-05]\n",
      " [ 2.8600637e-03]\n",
      " [ 4.7494881e-03]\n",
      " [ 2.4589738e-03]\n",
      " [-5.4864660e-03]\n",
      " [ 1.6983965e-03]\n",
      " [-4.6431151e-04]\n",
      " [ 3.7223682e-02]\n",
      " [ 3.7270207e-02]]\n",
      "[array([[-1.1855693e-05],\n",
      "       [ 2.8600637e-03],\n",
      "       [ 4.7494881e-03],\n",
      "       [ 2.4589738e-03],\n",
      "       [-5.4864660e-03],\n",
      "       [ 1.6983965e-03],\n",
      "       [-4.6431151e-04],\n",
      "       [ 3.7223682e-02],\n",
      "       [ 3.7270207e-02]], dtype=float32)]\n",
      "Epoch 800 MSE = 0.5340092\n",
      "[[-1.13970455e-05]\n",
      " [ 3.01306159e-03]\n",
      " [ 4.13528830e-03]\n",
      " [ 9.81118763e-04]\n",
      " [-3.74479755e-03]\n",
      " [ 1.46722561e-03]\n",
      " [-4.14510083e-04]\n",
      " [ 3.29514034e-02]\n",
      " [ 3.29237133e-02]]\n",
      "[array([[-1.13970455e-05],\n",
      "       [ 3.01306159e-03],\n",
      "       [ 4.13528830e-03],\n",
      "       [ 9.81118763e-04],\n",
      "       [-3.74479755e-03],\n",
      "       [ 1.46722561e-03],\n",
      "       [-4.14510083e-04],\n",
      "       [ 3.29514034e-02],\n",
      "       [ 3.29237133e-02]], dtype=float32)]\n",
      "Epoch 900 MSE = 0.5320459\n",
      "[[-1.1349737e-05]\n",
      " [ 3.0918657e-03]\n",
      " [ 3.6092121e-03]\n",
      " [-1.7702152e-04]\n",
      " [-2.3444449e-03]\n",
      " [ 1.2732481e-03]\n",
      " [-3.7135734e-04]\n",
      " [ 2.9206842e-02]\n",
      " [ 2.9120347e-02]]\n",
      "[array([[-1.1349737e-05],\n",
      "       [ 3.0918657e-03],\n",
      "       [ 3.6092121e-03],\n",
      "       [-1.7702152e-04],\n",
      "       [-2.3444449e-03],\n",
      "       [ 1.2732481e-03],\n",
      "       [-3.7135734e-04],\n",
      "       [ 2.9206842e-02],\n",
      "       [ 2.9120347e-02]], dtype=float32)]\n",
      "Epoch 1000 MSE = 0.5305077\n",
      "[[-1.1303171e-05]\n",
      " [ 3.1132493e-03]\n",
      " [ 3.1547777e-03]\n",
      " [-1.0722711e-03]\n",
      " [-1.2278772e-03]\n",
      " [ 1.1074179e-03]\n",
      " [-3.3330001e-04]\n",
      " [ 2.5919162e-02]\n",
      " [ 2.5789879e-02]]\n",
      "[array([[-1.1303171e-05],\n",
      "       [ 3.1132493e-03],\n",
      "       [ 3.1547777e-03],\n",
      "       [-1.0722711e-03],\n",
      "       [-1.2278772e-03],\n",
      "       [ 1.1074179e-03],\n",
      "       [-3.3330001e-04],\n",
      "       [ 2.5919162e-02],\n",
      "       [ 2.5789879e-02]], dtype=float32)]\n",
      "Epoch 1100 MSE = 0.52929586\n",
      "[[-1.1302385e-05]\n",
      " [ 3.0884908e-03]\n",
      " [ 2.7615349e-03]\n",
      " [-1.7523065e-03]\n",
      " [-3.4605010e-04]\n",
      " [ 9.6458272e-04]\n",
      " [-2.9945024e-04]\n",
      " [ 2.3030404e-02]\n",
      " [ 2.2868555e-02]]\n",
      "[array([[-1.1302385e-05],\n",
      "       [ 3.0884908e-03],\n",
      "       [ 2.7615349e-03],\n",
      "       [-1.7523065e-03],\n",
      "       [-3.4605010e-04],\n",
      "       [ 9.6458272e-04],\n",
      "       [-2.9945024e-04],\n",
      "       [ 2.3030404e-02],\n",
      "       [ 2.2868555e-02]], dtype=float32)]\n",
      "Epoch 1200 MSE = 0.52833605\n",
      "[[-1.1423195e-05]\n",
      " [ 3.0285332e-03]\n",
      " [ 2.4203688e-03]\n",
      " [-2.2565841e-03]\n",
      " [ 3.4219609e-04]\n",
      " [ 8.4117777e-04]\n",
      " [-2.6931349e-04]\n",
      " [ 2.0488322e-02]\n",
      " [ 2.0303192e-02]]\n",
      "[array([[-1.1423195e-05],\n",
      "       [ 3.0285332e-03],\n",
      "       [ 2.4203688e-03],\n",
      "       [-2.2565841e-03],\n",
      "       [ 3.4219609e-04],\n",
      "       [ 8.4117777e-04],\n",
      "       [-2.6931349e-04],\n",
      "       [ 2.0488322e-02],\n",
      "       [ 2.0303192e-02]], dtype=float32)]\n",
      "Epoch 1300 MSE = 0.52757233\n",
      "[[-1.1350028e-05]\n",
      " [ 2.9423942e-03]\n",
      " [ 2.1242145e-03]\n",
      " [-2.6179689e-03]\n",
      " [ 8.7106950e-04]\n",
      " [ 7.3461601e-04]\n",
      " [-2.4242207e-04]\n",
      " [ 1.8248066e-02]\n",
      " [ 1.8047931e-02]]\n",
      "[array([[-1.1350028e-05],\n",
      "       [ 2.9423942e-03],\n",
      "       [ 2.1242145e-03],\n",
      "       [-2.6179689e-03],\n",
      "       [ 8.7106950e-04],\n",
      "       [ 7.3461601e-04],\n",
      "       [-2.4242207e-04],\n",
      "       [ 1.8248066e-02],\n",
      "       [ 1.8047931e-02]], dtype=float32)]\n",
      "Epoch 1400 MSE = 0.5269619\n",
      "[[-1.13778515e-05]\n",
      " [ 2.83704884e-03]\n",
      " [ 1.86673703e-03]\n",
      " [-2.86349026e-03]\n",
      " [ 1.26997789e-03]\n",
      " [ 6.42299827e-04]\n",
      " [-2.18401226e-04]\n",
      " [ 1.62717029e-02]\n",
      " [ 1.60624254e-02]]\n",
      "[array([[-1.13778515e-05],\n",
      "       [ 2.83704884e-03],\n",
      "       [ 1.86673703e-03],\n",
      "       [-2.86349026e-03],\n",
      "       [ 1.26997789e-03],\n",
      "       [ 6.42299827e-04],\n",
      "       [-2.18401226e-04],\n",
      "       [ 1.62717029e-02],\n",
      "       [ 1.60624254e-02]], dtype=float32)]\n",
      "Epoch 1500 MSE = 0.5264731\n",
      "[[-1.1356140e-05]\n",
      " [ 2.7181073e-03]\n",
      " [ 1.6424927e-03]\n",
      " [-3.0163727e-03]\n",
      " [ 1.5623964e-03]\n",
      " [ 5.6229206e-04]\n",
      " [-1.9690249e-04]\n",
      " [ 1.4525625e-02]\n",
      " [ 1.4312113e-02]]\n",
      "[array([[-1.1356140e-05],\n",
      "       [ 2.7181073e-03],\n",
      "       [ 1.6424927e-03],\n",
      "       [-3.0163727e-03],\n",
      "       [ 1.5623964e-03],\n",
      "       [ 5.6229206e-04],\n",
      "       [-1.9690249e-04],\n",
      "       [ 1.4525625e-02],\n",
      "       [ 1.4312113e-02]], dtype=float32)]\n",
      "Epoch 1600 MSE = 0.5260783\n",
      "[[-1.1411903e-05]\n",
      " [ 2.5901741e-03]\n",
      " [ 1.4471265e-03]\n",
      " [-3.0951332e-03]\n",
      " [ 1.7686154e-03]\n",
      " [ 4.9283390e-04]\n",
      " [-1.7766898e-04]\n",
      " [ 1.2981556e-02]\n",
      " [ 1.2766827e-02]]\n",
      "[array([[-1.1411903e-05],\n",
      "       [ 2.5901741e-03],\n",
      "       [ 1.4471265e-03],\n",
      "       [-3.0951332e-03],\n",
      "       [ 1.7686154e-03],\n",
      "       [ 4.9283390e-04],\n",
      "       [-1.7766898e-04],\n",
      "       [ 1.2981556e-02],\n",
      "       [ 1.2766827e-02]], dtype=float32)]\n",
      "Epoch 1700 MSE = 0.52576005\n",
      "[[-1.13852147e-05]\n",
      " [ 2.45690066e-03]\n",
      " [ 1.27668958e-03]\n",
      " [-3.11578158e-03]\n",
      " [ 1.90511416e-03]\n",
      " [ 4.32528206e-04]\n",
      " [-1.60399286e-04]\n",
      " [ 1.16134072e-02]\n",
      " [ 1.14013655e-02]]\n",
      "[array([[-1.13852147e-05],\n",
      "       [ 2.45690066e-03],\n",
      "       [ 1.27668958e-03],\n",
      "       [-3.11578158e-03],\n",
      "       [ 1.90511416e-03],\n",
      "       [ 4.32528206e-04],\n",
      "       [-1.60399286e-04],\n",
      "       [ 1.16134072e-02],\n",
      "       [ 1.14013655e-02]], dtype=float32)]\n",
      "Epoch 1800 MSE = 0.5255015\n",
      "[[-1.1287630e-05]\n",
      " [ 2.3212114e-03]\n",
      " [ 1.1276832e-03]\n",
      " [-3.0907008e-03]\n",
      " [ 1.9860743e-03]\n",
      " [ 3.8013549e-04]\n",
      " [-1.4488705e-04]\n",
      " [ 1.0400328e-02]\n",
      " [ 1.0193130e-02]]\n",
      "[array([[-1.1287630e-05],\n",
      "       [ 2.3212114e-03],\n",
      "       [ 1.1276832e-03],\n",
      "       [-3.0907008e-03],\n",
      "       [ 1.9860743e-03],\n",
      "       [ 3.8013549e-04],\n",
      "       [-1.4488705e-04],\n",
      "       [ 1.0400328e-02],\n",
      "       [ 1.0193130e-02]], dtype=float32)]\n",
      "Epoch 1900 MSE = 0.52529186\n",
      "[[-1.1369499e-05]\n",
      " [ 2.1856737e-03]\n",
      " [ 9.9738361e-04]\n",
      " [-3.0306664e-03]\n",
      " [ 2.0227181e-03]\n",
      " [ 3.3450173e-04]\n",
      " [-1.3097901e-04]\n",
      " [ 9.3235625e-03]\n",
      " [ 9.1221621e-03]]\n",
      "[array([[-1.1369499e-05],\n",
      "       [ 2.1856737e-03],\n",
      "       [ 9.9738361e-04],\n",
      "       [-3.0306664e-03],\n",
      "       [ 2.0227181e-03],\n",
      "       [ 3.3450173e-04],\n",
      "       [-1.3097901e-04],\n",
      "       [ 9.3235625e-03],\n",
      "       [ 9.1221621e-03]], dtype=float32)]\n",
      "Best theta:\n",
      "[[ 2.0685525e+00]\n",
      " [ 8.5579723e-01]\n",
      " [ 1.2668240e-01]\n",
      " [-3.0933258e-01]\n",
      " [ 3.3943361e-01]\n",
      " [-1.9577104e-03]\n",
      " [-4.0555313e-02]\n",
      " [-8.1749099e-01]\n",
      " [-7.9091966e-01]]\n"
     ]
    }
   ],
   "source": [
    "def reset_graph(seed=42):\n",
    "    tf.reset_default_graph()\n",
    "    tf.set_random_seed(seed)\n",
    "    np.random.seed(seed)\n",
    "reset_graph()\n",
    "\n",
    "n_epochs = 2000\n",
    "learning_rate = 0.01\n",
    "\n",
    "X= tf.constant(scaled_housing_data_plus_bias, dtype=tf.float32, name=\"X\")\n",
    "y = tf.constant(housing.target.reshape(-1, 1), dtype=tf.float32, name=\"y\")\n",
    "theta = tf.Variable(tf.random_uniform([n + 1, 1], -0.9, 0.9, seed=42))\n",
    "y_pred = tf.matmul(X, theta, name=\"predictions\")\n",
    "\n",
    "error = y_pred - y\n",
    "mse = tf.reduce_mean(tf.square(error), name=\"mse\")\n",
    "\n",
    "gradients = tf.gradients(mse, [theta])[0]\n",
    "g1 = tf.gradients(mse, [theta])\n",
    "\n",
    "training_op = tf.assign(theta, theta - learning_rate * gradients)\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "\n",
    "    for epoch in range(n_epochs):\n",
    "        if epoch % 100 == 0:\n",
    "            print(\"Epoch\", epoch, \"MSE =\", mse.eval())\n",
    "            print(sess.run(gradients))\n",
    "            print(sess.run(g1))\n",
    "        sess.run(training_op)\n",
    "    \n",
    "    best_theta = theta.eval()\n",
    "\n",
    "print(\"Best theta:\")\n",
    "print(best_theta)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using an Optimizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 MSE = 8.6325445\n",
      "Epoch 100 MSE = 0.7095024\n",
      "Epoch 200 MSE = 0.5682746\n",
      "Epoch 300 MSE = 0.55664164\n",
      "Epoch 400 MSE = 0.54944104\n",
      "Epoch 500 MSE = 0.54396886\n",
      "Epoch 600 MSE = 0.53976834\n",
      "Epoch 700 MSE = 0.5365259\n",
      "Epoch 800 MSE = 0.5340092\n",
      "Epoch 900 MSE = 0.5320459\n",
      "Epoch 1000 MSE = 0.5305077\n",
      "Epoch 1100 MSE = 0.52929586\n",
      "Epoch 1200 MSE = 0.52833605\n",
      "Epoch 1300 MSE = 0.52757233\n",
      "Epoch 1400 MSE = 0.5269619\n",
      "Epoch 1500 MSE = 0.5264731\n",
      "Epoch 1600 MSE = 0.5260783\n",
      "Epoch 1700 MSE = 0.52576005\n",
      "Epoch 1800 MSE = 0.5255015\n",
      "Epoch 1900 MSE = 0.52529186\n",
      "Best theta:\n",
      "[[ 2.0685525e+00]\n",
      " [ 8.5579723e-01]\n",
      " [ 1.2668240e-01]\n",
      " [-3.0933258e-01]\n",
      " [ 3.3943361e-01]\n",
      " [-1.9577104e-03]\n",
      " [-4.0555313e-02]\n",
      " [-8.1749099e-01]\n",
      " [-7.9091966e-01]]\n"
     ]
    }
   ],
   "source": [
    "reset_graph()\n",
    "n_epochs = 2000\n",
    "learning_rate = 0.01\n",
    "\n",
    "X = tf.constant(scaled_housing_data_plus_bias, dtype=tf.float32, name=\"X\")\n",
    "y = tf.constant(housing.target.reshape(-1, 1), dtype=tf.float32, name=\"y\")\n",
    "theta = tf.Variable(tf.random_uniform([n + 1, 1], -0.9, 0.9, seed=42))\n",
    "y_pred = tf.matmul(X, theta, name=\"predictions\")\n",
    "error = y_pred - y\n",
    "mse = tf.reduce_mean(tf.square(error), name=\"mse\")\n",
    "\n",
    "optimizer  = tf.train.GradientDescentOptimizer(learning_rate=learning_rate)\n",
    "training_op = optimizer.minimize(mse)\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "\n",
    "    for epoch in range(n_epochs):\n",
    "        if epoch % 100 == 0:\n",
    "            print(\"Epoch\", epoch, \"MSE =\", mse.eval())\n",
    "        sess.run(training_op)\n",
    "    \n",
    "    best_theta = theta.eval()\n",
    "\n",
    "print(\"Best theta:\")\n",
    "print(best_theta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 MSE = 8.6325445\n",
      "Epoch 100 MSE = 2.4318814\n",
      "Epoch 200 MSE = 0.9845251\n",
      "Epoch 300 MSE = 0.608887\n",
      "Epoch 400 MSE = 0.5355876\n",
      "Epoch 500 MSE = 0.52558774\n",
      "Epoch 600 MSE = 0.5244939\n",
      "Epoch 700 MSE = 0.5243536\n",
      "Epoch 800 MSE = 0.52432764\n",
      "Epoch 900 MSE = 0.5243219\n",
      "Epoch 1000 MSE = 0.5243211\n",
      "Epoch 1100 MSE = 0.52432114\n",
      "Epoch 1200 MSE = 0.52432066\n",
      "Epoch 1300 MSE = 0.52432096\n",
      "Epoch 1400 MSE = 0.52432054\n",
      "Epoch 1500 MSE = 0.5243205\n",
      "Epoch 1600 MSE = 0.52432054\n",
      "Epoch 1700 MSE = 0.5243205\n",
      "Epoch 1800 MSE = 0.52432054\n",
      "Epoch 1900 MSE = 0.52432054\n",
      "Best theta:\n",
      "[[ 2.068555  ]\n",
      " [ 0.8296182 ]\n",
      " [ 0.1187515 ]\n",
      " [-0.2655253 ]\n",
      " [ 0.30569488]\n",
      " [-0.00450304]\n",
      " [-0.03932624]\n",
      " [-0.8998872 ]\n",
      " [-0.87054247]]\n"
     ]
    }
   ],
   "source": [
    "reset_graph()\n",
    "n_epochs = 2000\n",
    "learning_rate = 0.01\n",
    "\n",
    "X = tf.constant(scaled_housing_data_plus_bias, dtype=tf.float32, name=\"X\")\n",
    "y = tf.constant(housing.target.reshape(-1, 1), dtype=tf.float32, name=\"y\")\n",
    "theta = tf.Variable(tf.random_uniform([n + 1, 1], -0.9, 0.9, seed=42))\n",
    "y_pred = tf.matmul(X, theta, name=\"predictions\")\n",
    "error = y_pred - y\n",
    "mse = tf.reduce_mean(tf.square(error), name=\"mse\")\n",
    "\n",
    "optimizer  = tf.train.AdamOptimizer(learning_rate=learning_rate)\n",
    "training_op = optimizer.minimize(mse)\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "\n",
    "    for epoch in range(n_epochs):\n",
    "        if epoch % 100 == 0:\n",
    "            print(\"Epoch\", epoch, \"MSE =\", mse.eval())\n",
    "        sess.run(training_op)\n",
    "    \n",
    "    best_theta = theta.eval()\n",
    "\n",
    "print(\"Best theta:\")\n",
    "print(best_theta)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 将数据提供给训练算法Feeding data to the training algorithm\n",
    "\n",
    "使用 placeholder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 mse= 0.48219642\n",
      "Epoch 1 mse= 0.65663743\n",
      "Epoch 2 mse= 0.48741966\n",
      "Epoch 3 mse= 0.6732495\n",
      "Epoch 4 mse= 0.42330834\n",
      "Epoch 5 mse= 0.49597272\n",
      "Epoch 6 mse= 0.34872764\n",
      "Epoch 7 mse= 0.39867553\n",
      "Epoch 8 mse= 0.6930215\n",
      "Epoch 9 mse= 0.37455258\n",
      "Best theta:\n",
      "[[ 2.0703187 ]\n",
      " [ 0.862098  ]\n",
      " [ 0.12252025]\n",
      " [-0.3086222 ]\n",
      " [ 0.3818825 ]\n",
      " [ 0.00437853]\n",
      " [-0.01234637]\n",
      " [-0.83555514]\n",
      " [-0.8045839 ]]\n"
     ]
    }
   ],
   "source": [
    "n_epochs = 2000\n",
    "learning_rate = 0.01\n",
    "\n",
    "reset_graph()\n",
    "\n",
    "X = tf.placeholder(tf.float32, shape=(None, n + 1), name=\"X\")\n",
    "y = tf.placeholder(tf.float32, shape=(None, 1), name=\"y\")\n",
    "theta = tf.Variable(tf.random_uniform([n + 1, 1], -0.9, 0.9, seed=42))\n",
    "\n",
    "y_pred = tf.matmul(X, theta, name=\"predictions\")\n",
    "error = y_pred - y\n",
    "mse = tf.reduce_mean(tf.square(error), name=\"mse\")\n",
    "\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=learning_rate)\n",
    "training_op = optimizer.minimize(mse)\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "n_epochs = 10\n",
    "batch_size = 100\n",
    "n_batches = int(np.ceil(m / batch_size)) # 取整\n",
    "\n",
    "def fetch_batch(epoch, batch_index, batch_size):\n",
    "    np.random.seed(epoch * n_batches + batch_index)  # \n",
    "    indices = np.random.randint(m, size=batch_size)  # \n",
    "    X_batch = scaled_housing_data_plus_bias[indices] # \n",
    "    y_batch = housing.target.reshape(-1, 1)[indices] # not shown\n",
    "    return X_batch, y_batch\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    \n",
    "    for epoch in range(n_epochs):\n",
    "        for batch_index in range(n_batches):\n",
    "            X_batch, y_batch = fetch_batch(epoch, batch_index, batch_size)\n",
    "            \n",
    "            if batch_index == int(m / batch_size):\n",
    "                print(\"Epoch\", epoch, \"mse=\", sess.run(mse, feed_dict={X: X_batch, y: y_batch}))\n",
    "            sess.run(training_op, feed_dict={X: X_batch, y: y_batch})\n",
    "            \n",
    "        best_theta = theta.eval()\n",
    "\n",
    "print(\"Best theta:\")\n",
    "print(best_theta)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## 保存模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 MSE = 8.6325445\n",
      "Epoch 100 MSE = 2.4318814\n",
      "Epoch 200 MSE = 0.9845251\n",
      "Epoch 300 MSE = 0.608887\n",
      "Epoch 400 MSE = 0.5355876\n",
      "Epoch 500 MSE = 0.52558774\n",
      "Epoch 600 MSE = 0.5244939\n",
      "Epoch 700 MSE = 0.5243536\n",
      "Epoch 800 MSE = 0.52432764\n",
      "Epoch 900 MSE = 0.5243219\n",
      "Epoch 1000 MSE = 0.5243211\n",
      "Epoch 1100 MSE = 0.52432114\n",
      "Epoch 1200 MSE = 0.52432066\n",
      "Epoch 1300 MSE = 0.52432096\n",
      "Epoch 1400 MSE = 0.52432054\n",
      "Epoch 1500 MSE = 0.5243205\n",
      "Epoch 1600 MSE = 0.52432054\n",
      "Epoch 1700 MSE = 0.5243205\n",
      "Epoch 1800 MSE = 0.52432054\n",
      "Epoch 1900 MSE = 0.52432054\n",
      "Best theta:\n",
      "[[ 2.068555  ]\n",
      " [ 0.8296182 ]\n",
      " [ 0.1187515 ]\n",
      " [-0.2655253 ]\n",
      " [ 0.30569488]\n",
      " [-0.00450304]\n",
      " [-0.03932624]\n",
      " [-0.8998872 ]\n",
      " [-0.87054247]]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "reset_graph()\n",
    "n_epochs = 2000\n",
    "learning_rate = 0.01\n",
    "\n",
    "X = tf.constant(scaled_housing_data_plus_bias, dtype=tf.float32, name=\"X\")\n",
    "y = tf.constant(housing.target.reshape(-1, 1), dtype=tf.float32, name=\"y\")\n",
    "theta = tf.Variable(tf.random_uniform([n + 1, 1], -0.9, 0.9, seed=42))\n",
    "y_pred = tf.matmul(X, theta, name=\"predictions\")\n",
    "error = y_pred - y\n",
    "mse = tf.reduce_mean(tf.square(error), name=\"mse\")\n",
    "\n",
    "optimizer  = tf.train.AdamOptimizer(learning_rate=learning_rate)\n",
    "training_op = optimizer.minimize(mse)\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "saver = tf.train.Saver()\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "\n",
    "    for epoch in range(n_epochs):\n",
    "        if epoch % 100 == 0:\n",
    "            print(\"Epoch\", epoch, \"MSE =\", mse.eval())\n",
    "            \n",
    "        sess.run(training_op)\n",
    "        save_path = saver.save(sess, os.path.join(os.getcwd(), '../models/train_002.ckpt'))\n",
    "    \n",
    "    best_theta = theta.eval()\n",
    "    save_path = saver.save(sess, os.path.join(os.getcwd(), '../models/train_002.ckpt'))\n",
    "print(\"Best theta:\")\n",
    "print(best_theta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ../models/train_002.ckpt\n",
      "[[ 2.068555  ]\n",
      " [ 0.8296182 ]\n",
      " [ 0.1187515 ]\n",
      " [-0.2655253 ]\n",
      " [ 0.30569488]\n",
      " [-0.00450304]\n",
      " [-0.03932624]\n",
      " [-0.8998872 ]\n",
      " [-0.87054247]]\n"
     ]
    }
   ],
   "source": [
    "#saver = tf.train.import_meta_graph(\"../models/train_002.ckpt.meta\")\n",
    "#theta = tf.get_default_graph().get_tensor_by_name(\"theta:0\")\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    saver.restore(sess, \"../models/train_002.ckpt\")\n",
    "    best_theta_restored = theta.eval()\n",
    "    print(best_theta_restored)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## 使用TensorBoard\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "reset_graph()\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "now = datetime.utcnow().strftime(\"%Y%m%d%H%M%S\")\n",
    "root_logdir = \"tf_logs\"\n",
    "logdir = \"{}/run-{}/\".format(root_logdir, now)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 2.0703337 ]\n",
      " [ 0.8637145 ]\n",
      " [ 0.12255151]\n",
      " [-0.31211874]\n",
      " [ 0.38510373]\n",
      " [ 0.00434168]\n",
      " [-0.01232954]\n",
      " [-0.83376896]\n",
      " [-0.8030471 ]]\n"
     ]
    }
   ],
   "source": [
    "X = tf.placeholder(tf.float32, shape=(None, n + 1), name=\"X\")\n",
    "y = tf.placeholder(tf.float32, shape=(None, 1), name=\"y\")\n",
    "theta = tf.Variable(tf.random_uniform([n + 1, 1], -1.0, 1.0, seed=42), name=\"theta\")\n",
    "y_pred = tf.matmul(X, theta, name=\"predictions\")\n",
    "error = y_pred - y\n",
    "mse = tf.reduce_mean(tf.square(error), name=\"mse\")\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=learning_rate)\n",
    "training_op = optimizer.minimize(mse)\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "mse_summary = tf.summary.scalar('MSE', mse)\n",
    "file_writer = tf.summary.FileWriter(logdir, tf.get_default_graph())\n",
    "\n",
    "n_epochs = 10\n",
    "batch_size = 100\n",
    "n_batches = int(np.ceil(m / batch_size))\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    \n",
    "    for epoch in range(n_epochs):\n",
    "        for batch_index in range(n_batches):\n",
    "            X_batch, y_batch = fetch_batch(epoch, batch_index, batch_size)\n",
    "            if batch_index % 10 == 0:\n",
    "                summary_str = mse_summary.eval(feed_dict={X: X_batch, y: y_batch})\n",
    "                step = epoch * n_batches + batch_index\n",
    "                file_writer.add_summary(summary_str, step)\n",
    "            sess.run(training_op, feed_dict={X: X_batch, y: y_batch})\n",
    "            \n",
    "    best_theta = theta.eval()\n",
    "    print(best_theta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "file_writer.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 命名空间"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best theta:\n",
      "[[ 2.0703337 ]\n",
      " [ 0.8637145 ]\n",
      " [ 0.12255151]\n",
      " [-0.31211874]\n",
      " [ 0.38510373]\n",
      " [ 0.00434168]\n",
      " [-0.01232954]\n",
      " [-0.83376896]\n",
      " [-0.8030471 ]]\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "now = datetime.utcnow().strftime(\"%Y%m%d%H%M%S\")\n",
    "root_logdir = \"tf_logs\"\n",
    "logdir = \"{}/run-{}/\".format(root_logdir, now)\n",
    "\n",
    "X = tf.placeholder(tf.float32, shape=(None, n + 1), name=\"X\")\n",
    "y = tf.placeholder(tf.float32, shape=(None, 1), name=\"y\")\n",
    "theta = tf.Variable(tf.random_uniform([n + 1, 1], -1.0, 1.0, seed=42), name=\"theta\")\n",
    "y_pred = tf.matmul(X, theta, name=\"predictions\")\n",
    "\n",
    "with tf.name_scope(\"loss\") as scope:\n",
    "    error = y_pred - y\n",
    "    mse = tf.reduce_mean(tf.square(error), name=\"mse\")\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=learning_rate)\n",
    "training_op = optimizer.minimize(mse)\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "mse_summary = tf.summary.scalar('MSE', mse)\n",
    "file_writer = tf.summary.FileWriter(logdir, tf.get_default_graph())\n",
    "\n",
    "n_epochs = 10\n",
    "batch_size = 100\n",
    "n_batches = int(np.ceil(m / batch_size))\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "\n",
    "    for epoch in range(n_epochs):\n",
    "        for batch_index in range(n_batches):\n",
    "            X_batch, y_batch = fetch_batch(epoch, batch_index, batch_size)\n",
    "            if batch_index % 10 == 0:\n",
    "                summary_str = mse_summary.eval(feed_dict={X: X_batch, y: y_batch})\n",
    "                step = epoch * n_batches + batch_index\n",
    "                file_writer.add_summary(summary_str, step)\n",
    "            sess.run(training_op, feed_dict={X: X_batch, y: y_batch})\n",
    "\n",
    "    best_theta = theta.eval()\n",
    "\n",
    "file_writer.flush()\n",
    "file_writer.close()\n",
    "print(\"Best theta:\")\n",
    "print(best_theta)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 共享变量\n",
    "using name scopes:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "这种方法就是 共用一个relu空间，每次循环创建一个relu变量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reset_graph(seed=42):\n",
    "    tf.reset_default_graph()\n",
    "    tf.set_random_seed(seed)\n",
    "    np.random.seed(seed)\n",
    "reset_graph()\n",
    "def relu(X):\n",
    "    with tf.variable_scope(\"relu\", reuse=True):\n",
    "        threshold = tf.get_variable(\"threshold\")\n",
    "        w_shape = int(X.get_shape()[1]), 1\n",
    "        w = tf.Variable(tf.random_normal(w_shape), name=\"weights\")\n",
    "        b = tf.Variable(0.0, name = \"bias\")\n",
    "        z = tf.add(tf.matmul(X, w), b, name=\"z\")\n",
    "        return tf.maximum(z, threshold, name=\"max\")\n",
    "n_features = 3   \n",
    "X = tf.placeholder(tf.float32, shape=(None, n_features), name = \"X\")\n",
    "with tf.variable_scope(\"relu\"):\n",
    "    threshold = tf.get_variable(\"threshold\", shape=(),\n",
    "                               initializer=tf.constant_initializer(0.0))\n",
    "relus = [relu(X) for relu_index in range(5)]\n",
    "output = tf.add_n(relus, name=\"output\")\n",
    "\n",
    "file_writer = tf.summary.FileWriter(\"logs/relu6\", tf.get_default_graph())\n",
    "file_writer.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "这种方法就是 共用第一个relu空间，每次循环创建一个relu变量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Variable relu/threshold already exists, disallowed. Did you mean to set reuse=True or reuse=tf.AUTO_REUSE in VarScope? Originally defined at:\n\n  File \"<ipython-input-10-ec588a0f4f97>\", line 18, in <module>\n    initializer=tf.constant_initializer(0.0))\n  File \"/home/bladeray/anaconda3/envs/tf/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2862, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"/home/bladeray/anaconda3/envs/tf/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2802, in run_ast_nodes\n    if self.run_code(code, result):\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-95228b1b5f4a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mrelu_index\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvariable_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"relu\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreuse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrelu_index\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mscope\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m         \u001b[0mrelus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_n\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrelus\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"output\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0mfile_writer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFileWriter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"logs/relu9\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_default_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-11-95228b1b5f4a>\u001b[0m in \u001b[0;36mrelu\u001b[0;34m(X)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     threshold = tf.get_variable(\"threshold\", shape=(),\n\u001b[0;32m----> 3\u001b[0;31m                                initializer=tf.constant_initializer(0.0))\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mw_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_shape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mw\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom_normal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"weights\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf/lib/python3.6/site-packages/tensorflow/python/ops/variable_scope.py\u001b[0m in \u001b[0;36mget_variable\u001b[0;34m(name, shape, dtype, initializer, regularizer, trainable, collections, caching_device, partitioner, validate_shape, use_resource, custom_getter, constraint)\u001b[0m\n\u001b[1;32m   1260\u001b[0m       \u001b[0mpartitioner\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpartitioner\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidate_shape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidate_shape\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1261\u001b[0m       \u001b[0muse_resource\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_resource\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcustom_getter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcustom_getter\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1262\u001b[0;31m       constraint=constraint)\n\u001b[0m\u001b[1;32m   1263\u001b[0m get_variable_or_local_docstring = (\n\u001b[1;32m   1264\u001b[0m     \"\"\"%s\n",
      "\u001b[0;32m~/anaconda3/envs/tf/lib/python3.6/site-packages/tensorflow/python/ops/variable_scope.py\u001b[0m in \u001b[0;36mget_variable\u001b[0;34m(self, var_store, name, shape, dtype, initializer, regularizer, reuse, trainable, collections, caching_device, partitioner, validate_shape, use_resource, custom_getter, constraint)\u001b[0m\n\u001b[1;32m   1095\u001b[0m           \u001b[0mpartitioner\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpartitioner\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidate_shape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidate_shape\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1096\u001b[0m           \u001b[0muse_resource\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_resource\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcustom_getter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcustom_getter\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1097\u001b[0;31m           constraint=constraint)\n\u001b[0m\u001b[1;32m   1098\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1099\u001b[0m   def _get_partitioned_variable(self,\n",
      "\u001b[0;32m~/anaconda3/envs/tf/lib/python3.6/site-packages/tensorflow/python/ops/variable_scope.py\u001b[0m in \u001b[0;36mget_variable\u001b[0;34m(self, name, shape, dtype, initializer, regularizer, reuse, trainable, collections, caching_device, partitioner, validate_shape, use_resource, custom_getter, constraint)\u001b[0m\n\u001b[1;32m    433\u001b[0m           \u001b[0mcaching_device\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcaching_device\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpartitioner\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpartitioner\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    434\u001b[0m           \u001b[0mvalidate_shape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidate_shape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_resource\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_resource\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 435\u001b[0;31m           constraint=constraint)\n\u001b[0m\u001b[1;32m    436\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    437\u001b[0m   def _get_partitioned_variable(\n",
      "\u001b[0;32m~/anaconda3/envs/tf/lib/python3.6/site-packages/tensorflow/python/ops/variable_scope.py\u001b[0m in \u001b[0;36m_true_getter\u001b[0;34m(name, shape, dtype, initializer, regularizer, reuse, trainable, collections, caching_device, partitioner, validate_shape, use_resource, constraint)\u001b[0m\n\u001b[1;32m    402\u001b[0m           \u001b[0mtrainable\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrainable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcollections\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcollections\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    403\u001b[0m           \u001b[0mcaching_device\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcaching_device\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidate_shape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidate_shape\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 404\u001b[0;31m           use_resource=use_resource, constraint=constraint)\n\u001b[0m\u001b[1;32m    405\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    406\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcustom_getter\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf/lib/python3.6/site-packages/tensorflow/python/ops/variable_scope.py\u001b[0m in \u001b[0;36m_get_single_variable\u001b[0;34m(self, name, shape, dtype, initializer, regularizer, partition_info, reuse, trainable, collections, caching_device, validate_shape, use_resource, constraint)\u001b[0m\n\u001b[1;32m    741\u001b[0m                          \u001b[0;34m\"reuse=tf.AUTO_REUSE in VarScope? \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    742\u001b[0m                          \"Originally defined at:\\n\\n%s\" % (\n\u001b[0;32m--> 743\u001b[0;31m                              name, \"\".join(traceback.format_list(tb))))\n\u001b[0m\u001b[1;32m    744\u001b[0m       \u001b[0mfound_var\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_vars\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    745\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_compatible_with\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfound_var\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_shape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Variable relu/threshold already exists, disallowed. Did you mean to set reuse=True or reuse=tf.AUTO_REUSE in VarScope? Originally defined at:\n\n  File \"<ipython-input-10-ec588a0f4f97>\", line 18, in <module>\n    initializer=tf.constant_initializer(0.0))\n  File \"/home/bladeray/anaconda3/envs/tf/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2862, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"/home/bladeray/anaconda3/envs/tf/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2802, in run_ast_nodes\n    if self.run_code(code, result):\n"
     ]
    }
   ],
   "source": [
    "def relu(X):\n",
    "    threshold = tf.get_variable(\"threshold\", shape=(),\n",
    "                               initializer=tf.constant_initializer(0.0))\n",
    "    w_shape = (int(X.get_shape()[1]), 1)\n",
    "    w = tf.Variable(tf.random_normal(w_shape), name=\"weights\")\n",
    "    b = tf.Variable(0.0, name=\"bias\")\n",
    "    z = tf.add(tf.matmul(X, w), b, name=\"z\")\n",
    "    return tf.maximum(z, threshold, name=\"max\")\n",
    "\n",
    "X = tf.placeholder(tf.float32, shape=(None, n_features), name=\"X\")\n",
    "relus = []\n",
    "for relu_index in range(5):\n",
    "    with tf.variable_scope(\"relu\", reuse=(relu_index >= 1)) as scope:\n",
    "        relus.append(relu(X))\n",
    "output = tf.add_n(relus, name=\"output\")\n",
    "file_writer = tf.summary.FileWriter(\"logs/relu9\", tf.get_default_graph())\n",
    "file_writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
